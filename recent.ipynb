{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: \"made code on github only available for Colab usage, will remove it afterwards again\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## commands for training models and generating saved models (for analysing step)\n",
    "Appendix:\n",
    "\n",
    "\"For p(z) = N (z; 0, diag(σ)), experiments were run with \n",
    "\n",
    "a batch size of 64 and for 20 epochs. For p(z) = 􏰐d STUDENT-T(zd; ν), \n",
    "\n",
    "experiments were run with a batch size of 256 and for 40 epochs\"\n",
    "\n",
    "### T-Student's with different degrees of freedom\n",
    "```\n",
    "# here batch size and nb epochs different; choose anyway 20, otherwise too much time\n",
    "DF=2; python main.py --cuda-dev=4 --name dsprites_beta_1_pz_st_$DF --model dsprites \\\n",
    "    --skip-test --epochs 20 --lr 1e-4 --batch-size 256 --latent-dim 10 --beta 1. --prior StudentT --df $DF\n",
    "DF=5; python main.py --cuda-dev=4 --name dsprites_beta_1_pz_st_$DF --model dsprites \\\n",
    "    --skip-test --epochs 20 --lr 1e-4 --batch-size 256 --latent-dim 10 --beta 1. --prior StudentT --df $DF\n",
    "DF=9; python main.py --cuda-dev=2 --name dsprites_beta_1_pz_st_$DF --model dsprites \\\n",
    "    --skip-test --epochs 20 --lr 1e-4 --batch-size 256 --latent-dim 10 --beta 1. --prior StudentT --df $DF\n",
    "DF=12; python main.py --cuda-dev=2 --name dsprites_beta_1_pz_st_$DF --model dsprites \\\n",
    "    --skip-test --epochs 20 --lr 1e-4 --batch-size 256 --latent-dim 10 --beta 1. --prior StudentT --df $DF\n",
    "DF=9999; python main.py --cuda-dev=6 --name dsprites_beta_1_pz_st_$DF --model dsprites \\\n",
    "    --skip-test --epochs 20 --lr 1e-4 --batch-size 256 --latent-dim 10 --beta 1. --prior StudentT --df $DF\n",
    "\n",
    "```\n",
    "\n",
    "### Isotropic gaussian or anistropic gaussian with learned or fixed PCA\n",
    "\n",
    "```\n",
    "\n",
    "BETA=1 python main.py --cuda-dev=8 --name dsprites_beta_$BETA\\_pz_norm_iso --model dsprites \\\n",
    "    --skip-test --epochs 20 --lr 1e-4 --batch-size 64 --latent-dim 10 --beta $BETA --prior-variance iso\n",
    "BETA=1 python main.py --cuda-dev=8 --name dsprites_beta_$BETA\\_pz_norm_pca --model dsprites \\\n",
    "    --skip-test --epochs 20 --lr 1e-4 --batch-size 64 --latent-dim 10 --beta $BETA --prior-variance pca\n",
    "BETA=1 python main.py --cuda-dev=8 --name dsprites_beta_$BETA\\_pz_norm_pca_learn --model dsprites \\\n",
    "    --skip-test --epochs 20 --lr 1e-4 --batch-size 64 --latent-dim 10 --beta $BETA --prior-variance pca \\\n",
    "    --learn-prior-variance\n",
    "\n",
    "# --- done\n",
    "\n",
    "BETA=2; python main.py --cuda-dev=6 --name dsprites_beta_$BETA\\_pz_norm_iso --model dsprites \\\n",
    "    --skip-test --epochs 20 --lr 1e-4 --batch-size 64 --latent-dim 10 --beta $BETA --prior-variance iso\n",
    "BETA=2; python main.py --cuda-dev=7 --name dsprites_beta_$BETA\\_pz_norm_pca --model dsprites \\\n",
    "    --skip-test --epochs 20 --lr 1e-4 --batch-size 64 --latent-dim 10 --beta $BETA --prior-variance pca\n",
    "BETA=2; python main.py --cuda-dev=8 --name dsprites_beta_$BETA\\_pz_norm_pca_learn --model dsprites \\\n",
    "    --skip-test --epochs 20 --lr 1e-4 --batch-size 64 --latent-dim 10 --beta $BETA --prior-variance pca \\\n",
    "    --learn-prior-variance\n",
    "\n",
    "# --- done\n",
    "\n",
    "BETA=4; python main.py --cuda-dev=9 --name dsprites_beta_$BETA\\_pz_norm_iso --model dsprites \\\n",
    "    --skip-test --epochs 20 --lr 1e-4 --batch-size 64 --latent-dim 10 --beta $BETA --prior-variance iso\n",
    "BETA=4; python main.py --cuda-dev=6 --name dsprites_beta_$BETA\\_pz_norm_pca --model dsprites \\\n",
    "    --skip-test --epochs 20 --lr 1e-4 --batch-size 64 --latent-dim 10 --beta $BETA --prior-variance pca\n",
    "BETA=4; python main.py --cuda-dev=7 --name dsprites_beta_$BETA\\_pz_norm_pca_learn --model dsprites \\\n",
    "    --skip-test --epochs 20 --lr 1e-4 --batch-size 64 --latent-dim 10 --beta $BETA --prior-variance pca \\\n",
    "    --learn-prior-variance\n",
    "\n",
    "# --- done\n",
    "\n",
    "BETA=8; python main.py --cuda-dev=7 --name dsprites_beta_$BETA\\_pz_norm_iso --model dsprites \\\n",
    "    --skip-test --epochs 20 --lr 1e-4 --batch-size 64 --latent-dim 10 --beta $BETA --prior-variance iso\n",
    "BETA=8; python main.py --cuda-dev=8 --name dsprites_beta_$BETA\\_pz_norm_pca --model dsprites \\\n",
    "    --skip-test --epochs 20 --lr 1e-4 --batch-size 64 --latent-dim 10 --beta $BETA --prior-variance pca\n",
    "BETA=8; python main.py --cuda-dev=6 --name dsprites_beta_$BETA\\_pz_norm_pca_learn --model dsprites \\\n",
    "    --skip-test --epochs 20 --lr 1e-4 --batch-size 64 --latent-dim 10 --beta $BETA --prior-variance pca \\\n",
    "    --learn-prior-variance\n",
    "\n",
    "# --- done\n",
    "\n",
    "BETA=16; python main.py --cuda-dev=8 --name dsprites_beta_$BETA\\_pz_norm_iso --model dsprites \\\n",
    "    --skip-test --epochs 20 --lr 1e-4 --batch-size 64 --latent-dim 10 --beta $BETA --prior-variance iso\n",
    "BETA=16; python main.py --cuda-dev=8 --name dsprites_beta_$BETA\\_pz_norm_pca --model dsprites \\\n",
    "    --skip-test --epochs 20 --lr 1e-4 --batch-size 64 --latent-dim 10 --beta $BETA --prior-variance pca\n",
    "BETA=16; python main.py --cuda-dev=6 --name dsprites_beta_$BETA\\_pz_norm_pca_learn --model dsprites \\\n",
    "    --skip-test --epochs 20 --lr 1e-4 --batch-size 64 --latent-dim 10 --beta $BETA --prior-variance pca \\\n",
    "    --learn-prior-variance\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('src')\n",
    "import analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_experiments = '../experiments'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dsprites_beta_2_pz_norm_pca\n",
      "p(z):\n",
      "<class 'torch.distributions.normal.Normal'>\n",
      "(tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0.6882, 0.7913, 0.7979, 0.9221, 0.9242, 0.9248, 0.9362, 1.2132, 1.2307,\n",
      "         1.3569]]))\n",
      "q(z|x):\n",
      "<class 'torch.distributions.normal.Normal'>\n",
      "Load training data...\n",
      "Load testing data...\n",
      "Loss: 74.4 Recon: -36.8 KL: 18.8 Reg: 0.000\n",
      "Disentanglement: 0.631 (wo OT 0.629)\n",
      "dsprites_beta_4_pz_norm_pca\n",
      "p(z):\n",
      "<class 'torch.distributions.normal.Normal'>\n",
      "(tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0.6882, 0.7913, 0.7979, 0.9221, 0.9242, 0.9248, 0.9362, 1.2132, 1.2307,\n",
      "         1.3569]]))\n",
      "q(z|x):\n",
      "<class 'torch.distributions.normal.Normal'>\n",
      "Load training data...\n",
      "Load testing data...\n",
      "Loss: 108.7 Recon: -54.4 KL: 13.6 Reg: 0.000\n",
      "Disentanglement: 0.714 (wo OT 0.714)\n",
      "dsprites_beta_4_pz_norm_pca_learn\n",
      "p(z):\n",
      "<class 'torch.distributions.normal.Normal'>\n",
      "(tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0.6882, 0.7913, 0.7979, 0.9221, 0.9242, 0.9248, 0.9362, 1.2132, 1.2307,\n",
      "         1.3569]], grad_fn=<SqrtBackward>))\n",
      "q(z|x):\n",
      "<class 'torch.distributions.normal.Normal'>\n",
      "Load training data...\n",
      "Load testing data...\n",
      "Loss: 107.8 Recon: -50.7 KL: 14.3 Reg: 0.000\n",
      "Disentanglement: 0.812 (wo OT 0.809)\n",
      "dsprites_beta_1_pz_st_2\n",
      "p(z):\n",
      "<class 'torch.distributions.studentT.StudentT'>\n",
      "(tensor(2.), tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]))\n",
      "q(z|x):\n",
      "<class 'torch.distributions.normal.Normal'>\n",
      "Load training data...\n",
      "Load testing data...\n",
      "Loss: 50.4 Recon: -23.7 KL: 26.7 Reg: 0.000\n",
      "Disentanglement: 0.780 (wo OT 0.751)\n",
      "dsprites_beta_16_pz_norm_pca\n",
      "p(z):\n",
      "<class 'torch.distributions.normal.Normal'>\n",
      "(tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0.6882, 0.7913, 0.7979, 0.9221, 0.9242, 0.9248, 0.9362, 1.2132, 1.2307,\n",
      "         1.3569]]))\n",
      "q(z|x):\n",
      "<class 'torch.distributions.normal.Normal'>\n",
      "Load training data...\n",
      "Load testing data...\n",
      "Loss: 218.8 Recon: -121.9 KL: 6.1 Reg: 0.000\n",
      "Disentanglement: 0.785 (wo OT 0.783)\n",
      "dsprites_beta_1_pz_st_9999\n",
      "p(z):\n",
      "<class 'torch.distributions.studentT.StudentT'>\n",
      "(tensor(9999.), tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]))\n",
      "q(z|x):\n",
      "<class 'torch.distributions.normal.Normal'>\n",
      "Load training data...\n",
      "Load testing data...\n",
      "Loss: 58.0 Recon: -32.7 KL: 25.2 Reg: 0.000\n",
      "Disentanglement: 0.768 (wo OT 0.766)\n",
      "dsprites_beta_1_pz_norm_pca\n",
      "p(z):\n",
      "<class 'torch.distributions.normal.Normal'>\n",
      "(tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0.6882, 0.7913, 0.7979, 0.9221, 0.9242, 0.9248, 0.9362, 1.2132, 1.2307,\n",
      "         1.3569]]))\n",
      "q(z|x):\n",
      "<class 'torch.distributions.normal.Normal'>\n",
      "Load training data...\n",
      "Load testing data...\n",
      "Loss: 51.4 Recon: -25.5 KL: 25.8 Reg: 0.000\n",
      "Disentanglement: 0.732 (wo OT 0.726)\n",
      "dsprites_beta_8_pz_norm_pca\n",
      "p(z):\n",
      "<class 'torch.distributions.normal.Normal'>\n",
      "(tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0.6882, 0.7913, 0.7979, 0.9221, 0.9242, 0.9248, 0.9362, 1.2132, 1.2307,\n",
      "         1.3569]]))\n",
      "q(z|x):\n",
      "<class 'torch.distributions.normal.Normal'>\n",
      "Load training data...\n",
      "Load testing data...\n",
      "Loss: 161.2 Recon: -80.5 KL: 10.1 Reg: 0.000\n",
      "Disentanglement: 0.664 (wo OT 0.664)\n",
      "dsprites_beta_2_pz_norm_iso\n",
      "p(z):\n",
      "<class 'torch.distributions.normal.Normal'>\n",
      "(tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]))\n",
      "q(z|x):\n",
      "<class 'torch.distributions.normal.Normal'>\n",
      "Load training data...\n",
      "Load testing data...\n",
      "Loss: 73.2 Recon: -33.9 KL: 19.6 Reg: 0.000\n",
      "Disentanglement: 0.811 (wo OT 0.813)\n",
      "dsprites_beta_1_pz_st_5\n",
      "p(z):\n",
      "<class 'torch.distributions.studentT.StudentT'>\n",
      "(tensor(5.), tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]))\n",
      "q(z|x):\n",
      "<class 'torch.distributions.normal.Normal'>\n",
      "Load training data...\n",
      "Load testing data...\n",
      "Loss: 50.0 Recon: -22.5 KL: 27.5 Reg: 0.000\n",
      "Disentanglement: 0.733 (wo OT 0.714)\n",
      "dsprites_beta_2_pz_norm_pca_learn\n",
      "p(z):\n",
      "<class 'torch.distributions.normal.Normal'>\n",
      "(tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0.6882, 0.7913, 0.7979, 0.9221, 0.9242, 0.9248, 0.9362, 1.2132, 1.2307,\n",
      "         1.3569]], grad_fn=<SqrtBackward>))\n",
      "q(z|x):\n",
      "<class 'torch.distributions.normal.Normal'>\n",
      "Load training data...\n",
      "Load testing data...\n",
      "Loss: 73.6 Recon: -33.5 KL: 20.0 Reg: 0.000\n",
      "Disentanglement: 0.863 (wo OT 0.866)\n",
      "dsprites_beta_16_pz_norm_pca_learn\n",
      "p(z):\n",
      "<class 'torch.distributions.normal.Normal'>\n",
      "(tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0.6882, 0.7913, 0.7979, 0.9221, 0.9242, 0.9248, 0.9362, 1.2132, 1.2307,\n",
      "         1.3569]], grad_fn=<SqrtBackward>))\n",
      "q(z|x):\n",
      "<class 'torch.distributions.normal.Normal'>\n",
      "Load training data...\n",
      "Load testing data...\n",
      "Loss: 217.7 Recon: -114.4 KL: 6.5 Reg: 0.000\n",
      "Disentanglement: 0.734 (wo OT 0.735)\n",
      "dsprites_beta_1_pz_norm_pca_learn\n",
      "p(z):\n",
      "<class 'torch.distributions.normal.Normal'>\n",
      "(tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0.6882, 0.7913, 0.7979, 0.9221, 0.9242, 0.9248, 0.9362, 1.2132, 1.2307,\n",
      "         1.3569]], grad_fn=<SqrtBackward>))\n",
      "q(z|x):\n",
      "<class 'torch.distributions.normal.Normal'>\n",
      "Load training data...\n",
      "Load testing data...\n",
      "Loss: 50.9 Recon: -23.7 KL: 27.2 Reg: 0.000\n",
      "Disentanglement: 0.842 (wo OT 0.840)\n",
      "dsprites_beta_4_pz_norm_iso\n",
      "p(z):\n",
      "<class 'torch.distributions.normal.Normal'>\n",
      "(tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]))\n",
      "q(z|x):\n",
      "<class 'torch.distributions.normal.Normal'>\n",
      "Load training data...\n",
      "Load testing data...\n",
      "Loss: 108.2 Recon: -50.1 KL: 14.5 Reg: 0.000\n",
      "Disentanglement: 0.686 (wo OT 0.689)\n",
      "dsprites_beta_1_pz_st_12\n",
      "p(z):\n",
      "<class 'torch.distributions.studentT.StudentT'>\n",
      "(tensor(12.), tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]))\n",
      "q(z|x):\n",
      "<class 'torch.distributions.normal.Normal'>\n",
      "Load training data...\n",
      "Load testing data...\n",
      "Loss: 59.6 Recon: -34.5 KL: 25.1 Reg: 0.000\n",
      "Disentanglement: 0.799 (wo OT 0.803)\n",
      "dsprites_beta_8_pz_norm_pca_learn\n",
      "p(z):\n",
      "<class 'torch.distributions.normal.Normal'>\n",
      "(tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[0.6882, 0.7913, 0.7979, 0.9221, 0.9242, 0.9248, 0.9362, 1.2132, 1.2307,\n",
      "         1.3569]], grad_fn=<SqrtBackward>))\n",
      "q(z|x):\n",
      "<class 'torch.distributions.normal.Normal'>\n",
      "Load training data...\n",
      "Load testing data...\n",
      "Loss: 159.6 Recon: -78.5 KL: 10.1 Reg: 0.000\n",
      "Disentanglement: 0.732 (wo OT 0.726)\n",
      "dsprites_beta_1_pz_st_9\n",
      "p(z):\n",
      "<class 'torch.distributions.studentT.StudentT'>\n",
      "(tensor(9.), tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]))\n",
      "q(z|x):\n",
      "<class 'torch.distributions.normal.Normal'>\n",
      "Load training data...\n",
      "Load testing data...\n",
      "Loss: 50.9 Recon: -23.6 KL: 27.3 Reg: 0.000\n",
      "Disentanglement: 0.746 (wo OT 0.737)\n",
      "dsprites_beta_16_pz_norm_iso\n",
      "p(z):\n",
      "<class 'torch.distributions.normal.Normal'>\n",
      "(tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]))\n",
      "q(z|x):\n",
      "<class 'torch.distributions.normal.Normal'>\n",
      "Load training data...\n",
      "Load testing data...\n",
      "Loss: 217.6 Recon: -113.3 KL: 6.5 Reg: 0.000\n",
      "Disentanglement: 0.799 (wo OT 0.808)\n",
      "dsprites_beta_8_pz_norm_iso\n",
      "p(z):\n",
      "<class 'torch.distributions.normal.Normal'>\n",
      "(tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]))\n",
      "q(z|x):\n",
      "<class 'torch.distributions.normal.Normal'>\n",
      "Load training data...\n",
      "Load testing data...\n",
      "Loss: 158.9 Recon: -79.4 KL: 9.9 Reg: 0.000\n",
      "Disentanglement: 0.730 (wo OT 0.734)\n",
      "dsprites_beta_1_pz_norm_iso\n",
      "p(z):\n",
      "<class 'torch.distributions.normal.Normal'>\n",
      "(tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]))\n",
      "q(z|x):\n",
      "<class 'torch.distributions.normal.Normal'>\n",
      "Load training data...\n",
      "Load testing data...\n",
      "Loss: 51.3 Recon: -23.5 KL: 27.7 Reg: 0.000\n",
      "Disentanglement: 0.707 (wo OT 0.705)\n"
     ]
    }
   ],
   "source": [
    "# calculate disentanglement for each experiment\n",
    "for exp_name in os.listdir(path_experiments):\n",
    "    print(exp_name)\n",
    "    sub_dirs = os.listdir('{}/{}'.format(path_experiments, exp_name))\n",
    "    # for each experiment, made only one run\n",
    "    assert len(sub_dirs) == 1\n",
    "    sub_dir = sub_dirs[0]\n",
    "    path = os.path.join(path_experiments, exp_name, sub_dir)\n",
    "    result = analyse.run(\n",
    "        path,\n",
    "        disentanglement=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'test_loss': [51.283004479938086],\n",
       "             'test_recon': [-23.542267998887432],\n",
       "             'test_kl': [27.74073648750782],\n",
       "             'test_reg': [0.0],\n",
       "             'test_disentanglement': [0.7054499983787537],\n",
       "             'test_disentanglement2': [0.7072499990463257]})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dsprites_beta_2_pz_norm_pca\n",
      "dsprites_beta_4_pz_norm_pca\n",
      "dsprites_beta_4_pz_norm_pca_learn\n",
      "dsprites_beta_1_pz_st_2\n",
      "dsprites_beta_16_pz_norm_pca\n",
      "dsprites_beta_1_pz_st_9999\n",
      "dsprites_beta_1_pz_norm_pca\n",
      "dsprites_beta_8_pz_norm_pca\n",
      "dsprites_beta_2_pz_norm_iso\n",
      "dsprites_beta_1_pz_st_5\n",
      "dsprites_beta_2_pz_norm_pca_learn\n",
      "dsprites_beta_16_pz_norm_pca_learn\n",
      "dsprites_beta_1_pz_norm_pca_learn\n",
      "dsprites_beta_4_pz_norm_iso\n",
      "dsprites_beta_1_pz_st_12\n",
      "dsprites_beta_8_pz_norm_pca_learn\n",
      "dsprites_beta_1_pz_st_9\n",
      "dsprites_beta_16_pz_norm_iso\n",
      "dsprites_beta_8_pz_norm_iso\n",
      "dsprites_beta_1_pz_norm_iso\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "# calculate disentanglement for each experiment\n",
    "for exp_name in os.listdir(path_experiments):\n",
    "    print(exp_name)\n",
    "    sub_dir = os.listdir('{}/{}'.format(path_experiments, exp_name))[0]\n",
    "    path = os.path.join(path_experiments, exp_name, sub_dir)\n",
    "    path_result = os.path.join(path, )\n",
    "#     results[exp_name] = torch.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.load(\n",
    "    '/export/home/vtschern/workspace/test/experiments/2020-03-30T01_28_17.273538zqphwnru/losses.rar'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
